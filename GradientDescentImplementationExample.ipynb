{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Implementing Gradient Descent Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importing dataset downloaded from https://stats.idre.ucla.edu/stat/data/binary.csv "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "admis=pd.read_csv('binary.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Cleaning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### One-Hot Encoding the rank using pandas' get_dummies method into 4 new columns and then concating these columns with the original dataset  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd_dum=pd.concat([admis,pd.get_dummies(admis['rank'],prefix='rank')],axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### We then drop the original rank table. Dummy Variables are the one that takes value either 0 or 1 indicating prescence or abscense of something. For example,categories 'dog' or 'not dog',the two are mutually exclusive. Hence it is used to sort data into mutual exclusive categories avoiding dependency between classes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data=pd_dum.drop('rank',axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### After that we standarize the GRE and GPA, i.e. scaling the values between  0 or 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "for field in ['gre', 'gpa']:\n",
    "    mean,std=data[field].mean(),data[field].std()\n",
    "    data.loc[:,field]=(data[field]-mean)/std\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Then we split the dataset into training and test data with 80:20 ratio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "sampleset=np.random.choice(data.index,int(len(data)*0.8),replace=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ABC\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:1: DeprecationWarning: \n",
      ".ix is deprecated. Please use\n",
      ".loc for label based indexing or\n",
      ".iloc for positional indexing\n",
      "\n",
      "See the documentation here:\n",
      "http://pandas.pydata.org/pandas-docs/stable/indexing.html#ix-indexer-is-deprecated\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    }
   ],
   "source": [
    "data_train,data_test=data.ix[sampleset],data.drop(sampleset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### After that we define features and targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "features,targets=data_train.drop('admit',axis=1),data_train['admit']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_test,targets_test=data_test.drop('admit',axis=1),data_test['admit']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Implementing gradient descent and training the network on  data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Algorithm to update weights\n",
    "### - Set the weight step to 0.\n",
    "### - For each record in training data:\n",
    "        -Do Forward Pass,i.e. calculating the output formula\n",
    "        -Calculating error term,i.e. = (target-output)*derivative of output function\n",
    "        -Update the weight step += error_term*x # x at i th step\n",
    "### - After that we update the weights w at i += alpha  *   weight_step at i  * x at i  / m\n",
    "      #alpha is the learning rate and m is the number of records\n",
    "### - Repeat above steps for e epochs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Activation function\n",
    "def sigmoid(x):\n",
    "    return 1/(1+np.exp(-x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(28)\n",
    "n_records,n_features=features.shape\n",
    "last_loss=None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "weights=np.random.normal(scale=1/n_features**0.5,size=n_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs=2000\n",
    "alpha=0.4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss= 0.2668565052671138\n",
      "Loss= 0.20730181092979488\n",
      "Loss= 0.19998882485260605\n",
      "Loss= 0.19838150365758972\n",
      "Loss= 0.19788959908604448\n",
      "Loss= 0.19770697756852962\n",
      "Loss= 0.19763046384076208\n",
      "Loss= 0.19759575420898717\n",
      "Loss= 0.1975791442932227\n",
      "Loss= 0.1975709018292245\n"
     ]
    }
   ],
   "source": [
    "for e in range(epochs):\n",
    "    del_weights=np.zeros(weights.shape)\n",
    "    for x,y in zip(features.values,targets):\n",
    "        h=np.dot(x,weights)\n",
    "        output=sigmoid(h)\n",
    "        error=y-output\n",
    "        error_term=error*output*(1-output) #derivative of sigmoid function is sigmoidfunction*(1-sigmoidfunction)\n",
    "        del_weights+=error_term*x\n",
    "    weights += alpha*del_weights/n_records\n",
    "\n",
    "    #After every 200 epoch printing meaning squared error and also displaying if the loss is increasing or decreasing\n",
    "    if e%(epochs/10)==0:\n",
    "        outz=sigmoid(np.dot(features,weights))\n",
    "        errorz=np.mean((targets-outz)**2)\n",
    "        if last_loss and last_loss<errorz:\n",
    "            print('Loss Increasing! Loss=',errorz)\n",
    "        else:\n",
    "            print('Loss=',errorz)\n",
    "        last_loss=errorz\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Since now we got our weights after training. Let's now check the accuracy on the test data we splited earlier.\n",
    "### Student Admitted = 1 and Student Not Admited = 0, hence probabilities closer to 1 predicts student admitted.\n",
    "### So all the probabilities > 0.5 convey student being admitted\n",
    "### So we make all the probabilities > 0.5 as 1 while the others 0 and save it as our predictions. And then check the accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_output=sigmoid(np.dot(features_test,weights))\n",
    "\n",
    "predictions=test_output>0.5\n",
    "\n",
    "accuracy=np.mean(predictions==targets_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.7875\n"
     ]
    }
   ],
   "source": [
    "print('Accuracy:',accuracy)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
